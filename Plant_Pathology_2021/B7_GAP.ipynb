{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-------------------\n# importing libraries\n#-------------------\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom kaggle_datasets import KaggleDatasets\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport PIL\nimport shutil\nimport csv\n\nimport os\nos.system('pip install /kaggle/input/keras-zip -q')\nos.system('pip install /kaggle/input/efficientnet-zip/ -q --no-deps')\n\nimport efficientnet.tfkeras as efn","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('plant-pathology-2021-fgvc8')\n\nTRAIN_PATH = GCS_DS_PATH + \"/train_images/\"\n\ntrain_df = pd.read_csv(\"../input/plant-pathology-2021-fgvc8/train.csv\")\n\ncount_dict = train_df.labels.value_counts()\nclasses = list(count_dict.index)\nclasses_count = list(count_dict.values)\nprint(\"Number of unique labels: \",len(classes))\n\nlabel2id = {\n    'scab': 0,\n    'frog_eye_leaf_spot' : 1,\n    'rust' : 2,\n    'complex' : 3,\n    'powdery_mildew' : 4,\n}\nNUM_CLASSES = len(label2id)    \nid2label = dict([(value, key) for key, value in label2id.items()])\ntrain_df[\"labels\"] = train_df[\"labels\"].map(lambda x : [i for i in x.split(\" \") if i != \"healthy\"])\ntrain_df[\"labels\"] = train_df[\"labels\"].map(lambda x : [label2id[i] for i in x])\n\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------\n#initialize constants\n#--------------\nHEIGHT,WIDTH = 512,512\nCHANNELS = 3\nBATCH_SIZE = 8 * strategy.num_replicas_in_sync\nSEED = 143\nSPLIT = int(0.9*len(train_df))\nAUTO = tf.data.experimental.AUTOTUNE\nSTEPS_PER_EPOCH  = SPLIT//BATCH_SIZE\nVALID_STEPS = (len(train_df)-SPLIT)//BATCH_SIZE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing Functions","metadata":{}},{"cell_type":"code","source":"# Preprocess the Image\ndef process_img(filepath,label):\n    image = tf.io.read_file(filepath)\n    image = tf.image.decode_jpeg(image, channels=CHANNELS)\n    image = tf.image.convert_image_dtype(image, tf.float32) \n    image = tf.image.resize(image, [HEIGHT,WIDTH])\n    return image,label\n\n# For Data Augmentation\ndef data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) \n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) \n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) \n        \n    \n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n        \n    \n    if p_crop > .7:\n        if p_crop > .9:\n            image = tf.image.central_crop(image, central_fraction=.7)\n        elif p_crop > .8:\n            image = tf.image.central_crop(image, central_fraction=.8)\n        else:\n            image = tf.image.central_crop(image, central_fraction=.9)\n    elif p_crop > .4:\n        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)\n        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])\n    \n    image = tf.image.resize(image, [HEIGHT,WIDTH])\n    return image,label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pipeline","metadata":{}},{"cell_type":"code","source":"files_ls = tf.io.gfile.glob(TRAIN_PATH + '*.jpg')\nlabels = np.zeros((len(train_df),NUM_CLASSES))\n\nfor i,file in enumerate(train_df.values):\n    labels[i][train_df.iloc[i][\"labels\"]] = 1\n    \ndataset = tf.data.Dataset.from_tensor_slices((files_ls,labels))\ndataset = dataset.map(process_img,num_parallel_calls=AUTO)\ndataset = dataset.map(data_augment,num_parallel_calls=AUTO)\n\ntrain_ds = dataset.take(SPLIT)\nval_ds = dataset.skip(SPLIT)\n\ntrain_ds = train_ds.cache().repeat().shuffle(2048).batch(BATCH_SIZE).prefetch(AUTO)\nval_ds = val_ds.cache().repeat().batch(BATCH_SIZE).prefetch(AUTO)\nprint(\"Data Pipeline\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def create_baseModel():\n    base_model = efn.EfficientNetB7(include_top=False,\n                                input_shape=[HEIGHT,WIDTH,CHANNELS],\n                                weights='noisy-student')\n    # Freeze the base model\n    base_model.trainable = False\n    return base_model\n\ndef get_trainable(model):\n    for layer in model.layers:\n        layer.trainable = True\n    \ndef create_model():\n    base_model = create_baseModel()\n    \n#     x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n#     x = tf.keras.layers.Dense(2560, activation ='relu')(x)\n#     x = tf.keras.layers.Dropout(0.5)(x)\n    \n    ################################ Version2 ###############################\n    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1280, activation ='relu')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n################################################################################\n    \n    outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=\"sigmoid\", dtype='float32')(x)\n\n    model = tf.keras.Model(inputs = base_model.input, outputs = outputs)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compiling the Model","metadata":{}},{"cell_type":"code","source":"import tensorflow_addons as tfa\nimport sklearn\n\ndef compile_model(model, lr=0.001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.BinaryCrossentropy()  \n    metrics = [\n    \n       tfa.metrics.F1Score(num_classes = NUM_CLASSES,average = \"macro\", name = \"f1_score\"),\n       tf.keras.metrics.BinaryAccuracy(name='acc')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Callbacks Function","metadata":{}},{"cell_type":"code","source":"METRIC = \"val_f1_score\"\n\ndef create_callbacks(metric = METRIC):\n    \n    cpk_path = './B7model.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor= metric,\n        mode='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor= metric,\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor= metric,\n        mode='max',\n        patience=10, \n        verbose=1\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]         \n    \n    return callbacks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# model = load_model(\"../input/sjmodel/best_model.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS= 30\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith strategy.scope():\n    \n    model = create_model()\n    model = compile_model(model, lr=0.001)\n    \n    callbacks = create_callbacks()\n    \n    history = model.fit(\n                        train_ds,\n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = val_ds,\n                        verbose=VERBOSE,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        validation_steps=VALID_STEPS\n                       )\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(hist):\n    history = hist\n    acc = history.history['acc']\n    val_acc = history.history['val_acc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(len(history.history['val_loss']))\n    plt.figure(figsize=(8, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, acc, label='Training Accuracy')\n    plt.plot(epochs_range, val_acc, label='Validation  Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation  Accuracy')\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_trainable(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS= 50\nVERBOSE =1\n\nwith strategy.scope():\n    \n    model = compile_model(model,lr= 0.00001)\n    \n    callbacks = create_callbacks()\n    \n    history_unfreeze = model.fit(\n                        train_ds,\n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = val_ds,\n                        verbose=VERBOSE,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        validation_steps=VALID_STEPS\n                       )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# History plotting","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history_unfreeze)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"# TEST_PATH = GCS_DS_PATH + \"/test_images/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = os.listdir('../input/plant-pathology-2021-fgvc8/test_images/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _parse(name):\n#     with open('../input/plant-pathology-2021-fgvc8/test_images/'+ name, \"rb\") as local_file:\n#         image_string = local_file.read()\n    image_string = tf.io.read_file('../input/plant-pathology-2021-fgvc8/test_images/' + name)\n    image_decoded = tf.image.decode_jpeg(image_string)\n    imgs = tf.image.resize(image_decoded, [WIDTH, HEIGHT])\n    return imgs/255\n\n\n\ndataset = tf.data.Dataset.from_tensor_slices((tf.constant(names)))\\\n                               .map(_parse, num_parallel_calls=tf.data.AUTOTUNE)\\\n                               .batch(32)\\\n                               .prefetch(tf.data.AUTOTUNE)\nprint(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(dataset, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_names=['scab','frog_eye_leaf_spot','rust','complex','powdery_mildew']\n\ny = np.around(y_pred)\ni = 0\nlabels = []\nfor i in range(len(y)):\n    check = 0\n    vec = str()\n    for j in range(len(label_names)):\n        if(y[i][j]==1):\n            check+=1\n            vec = vec + label_names[j] + \" \"\n    if(check==0):\n        vec = vec + 'healthy'\n    labels.append(vec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'image':names, 'labels':labels})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('./submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}